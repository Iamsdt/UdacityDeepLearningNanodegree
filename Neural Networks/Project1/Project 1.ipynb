{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T05:01:49.131937Z",
     "start_time": "2019-10-27T05:01:48.943613Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[0.5, -0.2, 0.1]])\n",
    "targets = np.array([[0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T05:18:37.817409Z",
     "start_time": "2019-10-27T05:18:37.803446Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes ** -0.5,\n",
    "                                                        (self.input_nodes, self.hidden_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes ** -0.5,\n",
    "                                                         (self.hidden_nodes, self.output_nodes))\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # sigmoid function\n",
    "        self.activation_function = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def train(self, features, targets):\n",
    "        \"\"\" Train the network on batch of features and targets.\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "\n",
    "            features: 2D array, each row is one data record, each column is a feature\n",
    "            targets: 1D array of target values\n",
    "\n",
    "        \"\"\"\n",
    "        n_records = features.shape[0]\n",
    "        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "        for X, y in zip(features, targets):\n",
    "            final_outputs, hidden_outputs = self.forward_pass_train(X)  # Implement the forward pass function below\n",
    "            # Implement the backproagation function below\n",
    "            delta_weights_i_h, delta_weights_h_o = self.backpropagation(final_outputs, hidden_outputs, X, y,\n",
    "                                                                        delta_weights_i_h, delta_weights_h_o)\n",
    "        self.update_weights(delta_weights_i_h, delta_weights_h_o, n_records)\n",
    "\n",
    "    def forward_pass_train(self, X):\n",
    "        \"\"\" Implement forward pass here\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            X: features batch\n",
    "\n",
    "        \"\"\"\n",
    "        # pass input x to the input node\n",
    "        # the output of input node will be the input for hidden node\n",
    "        hidden_inputs = np.dot(X, self.weights_input_to_hidden)\n",
    "        # pass hidden input to activation function\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # hidden output will be the input of this layer\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs, hidden_outputs\n",
    "\n",
    "\n",
    "    def backpropagation(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o):\n",
    "        ''' Implement backpropagation\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            final_outputs: output from forward pass\n",
    "            y: target (i.e. label) batch\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "\n",
    "        '''\n",
    "        #### Implement the backward pass here ####\n",
    "        ### Backward pass ###\n",
    "        # Error\n",
    "        print(final_outputs, hidden_outputs, X, y, self.weights_hidden_to_output)\n",
    "        \n",
    "        error = y - final_outputs\n",
    "        output_error_term = error * final_outputs * (1 - final_outputs)\n",
    "        \n",
    "        # hidden error\n",
    "        hidden_error = output_error_term * self.weights_hidden_to_output\n",
    "        hidden_error_term = hidden_error * hidden_outputs * (1 - hidden_outputs)\n",
    "        \n",
    "        print(hidden_error_term.shape)\n",
    "        print(hidden_outputs.shape)\n",
    "        print(delta_weights_i_h.shape)\n",
    "        # Weight step (input to hidden)\n",
    "        delta_weights_i_h += hidden_error_term * X # this line\n",
    "        # Weight step (hidden to output)\n",
    "        delta_weights_h_o += output_error_term * hidden_outputs\n",
    "        return delta_weights_i_h, delta_weights_h_o\n",
    "\n",
    "    def update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n",
    "        \"\"\" Update weights on gradient descent step\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            delta_weights_i_h: change in weights from input to hidden layers\n",
    "            delta_weights_h_o: change in weights from hidden to output layers\n",
    "            n_records: number of records\n",
    "\n",
    "        \"\"\"\n",
    "        # learning rate * avg weight (delta_weights_i_h/n_records)\n",
    "        self.weights_hidden_to_output += self.lr * delta_weights_h_o / n_records\n",
    "        self.weights_input_to_hidden += self.lr * delta_weights_i_h / n_records\n",
    "\n",
    "    def run(self, features):\n",
    "        \"\"\" Run a forward pass through the network with input features\n",
    "\n",
    "            Arguments\n",
    "            ---------\n",
    "            features: 1D array of feature values\n",
    "        \"\"\"\n",
    "\n",
    "        # pass input x to the input node\n",
    "        # the output of input node will be the input for hidden node\n",
    "        hidden_inputs = np.dot(features, self.weights_input_to_hidden)\n",
    "        # pass hidden input to activation function\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # hidden output will be the input of this layer\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs\n",
    "    \n",
    "net = NeuralNetwork(3, 2, 1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T05:18:40.145240Z",
     "start_time": "2019-10-27T05:18:40.131297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65870191] [0.45873533 0.56297788] [ 0.5 -0.2  0.1] [0.4] [[0.84647249]\n",
      " [0.47818579]]\n",
      "(2, 2)\n",
      "(2,)\n",
      "(3, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,2) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6a5b53c678eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-2c75831f5c4a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, features, targets)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# Implement the backproagation function below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             delta_weights_i_h, delta_weights_h_o = self.backpropagation(final_outputs, hidden_outputs, X, y,\n\u001b[1;32m---> 36\u001b[1;33m                                                                         delta_weights_i_h, delta_weights_h_o)\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_weights_i_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_weights_h_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_records\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-2c75831f5c4a>\u001b[0m in \u001b[0;36mbackpropagation\u001b[1;34m(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_weights_i_h\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m# Weight step (input to hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mdelta_weights_i_h\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mhidden_error_term\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m \u001b[1;31m# this line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Weight step (hidden to output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mdelta_weights_h_o\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0moutput_error_term\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mhidden_outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,2) (3,) "
     ]
    }
   ],
   "source": [
    "net.train(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
