# Gradient Descent

 **Gradient descent is** an optimization algorithm for finding the minimum of a function.

 ![Image result for Gradient Descent](https://miro.medium.com/max/1005/1*_6TVU8yGpXNYDkkpOfnJ6Q.png) 

# Calculation

![Calculation](https://github.com/Iamsdt/UdacityDeepLearningNanodegree/raw/master/img/gradient.png)

# Gradient Descent Algorithm

![1571460392302](img/Gradient%20Descent/1571460392302.png)

# Perceptron vs Gradient Descent

|                          Perceptron                          |                       Gradient Descent                       |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| not every point changes weights, only the miss classified ones | Every point change weights<br />W<sub>i</sub> = W + a(y-y`)x<sub>i</sub> |
|                  predict only one and zero                   |                 predict between zero and one                 |
|     If points are correctly classified, it's do nothing      | If points are correctly classified, it's still update weights |





