{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T09:47:46.043258Z",
     "start_time": "2019-11-22T09:47:44.896559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "            Conv2d-3           [-1, 64, 56, 56]          18,496\n",
      "       BatchNorm2d-4           [-1, 64, 56, 56]             128\n",
      "         MaxPool2d-5           [-1, 64, 28, 28]               0\n",
      "            Conv2d-6           [-1, 64, 26, 26]          36,928\n",
      "       BatchNorm2d-7           [-1, 64, 26, 26]             128\n",
      "         MaxPool2d-8           [-1, 64, 13, 13]               0\n",
      "            Conv2d-9          [-1, 128, 13, 13]          73,856\n",
      "      BatchNorm2d-10          [-1, 128, 13, 13]             256\n",
      "        MaxPool2d-11            [-1, 128, 6, 6]               0\n",
      "           Linear-12                  [-1, 512]       2,359,808\n",
      "          Dropout-13                  [-1, 512]               0\n",
      "           Linear-14                  [-1, 256]         131,328\n",
      "          Dropout-15                  [-1, 256]               0\n",
      "           Linear-16                  [-1, 133]          34,181\n",
      "================================================================\n",
      "Total params: 2,656,069\n",
      "Trainable params: 2,656,069\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 10.69\n",
      "Params size (MB): 10.13\n",
      "Estimated Total Size (MB): 21.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary as ts\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # cnn layers\n",
    "        nn.Conv2d()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(i3, 32, 3, stride = 2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride = 2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        \n",
    "        # batch normalization\n",
    "        self.batch1 = nn.BatchNorm2d(32)\n",
    "        self.batch2 = nn.BatchNorm2d(64)\n",
    "        self.batch3 = nn.BatchNorm2d(64)\n",
    "        self.batch4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        \n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(4608, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 133)\n",
    "        \n",
    "        #drop out layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # save the batch size of input tensor\n",
    "        shape = x.size(0)\n",
    "        # pass input tensor to the cnn layers\n",
    "        #in the first layer pooling is not used, its show improvement accuracy\n",
    "        x = F.relu(self.batch1(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.batch2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.batch3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.batch4(self.conv4(x))))\n",
    "        # flatten image input\n",
    "        x = x.view(shape, -1)\n",
    "        # pass to fully connected layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "    \n",
    "model = Net()\n",
    "ts.summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(loaders['train'])):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            ouput = model(data)\n",
    "            # calculate loss\n",
    "            loss = criterion(ouput, target)\n",
    "            #backward pass: backpropagation\n",
    "            loss.backward()\n",
    "            # update weight\n",
    "            optimizer.step()\n",
    "            # claulate train loss\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "             # forward pass\n",
    "            output = model(data)\n",
    "            # calculate loss\n",
    "            loss_p = criterion(output, target)\n",
    "            # update validation loss\n",
    "            valid_loss += loss_p.item() * data.size(0)\n",
    "            # calculate accuracy\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tAcc:{:.2f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            (correct / total * 100)))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('\\tValidation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The output is better than I expected\n",
    "\n",
    "1.   As validation loss is still decreasing, so more epoch mayebe inprove results\n",
    "2.  Add more fully connected layers\n",
    "3.  For human detection, use more complex model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
